# ğŸ· ClasificaciÃ³n de la Calidad del Vino â€“ Proyecto de Machine Learning

## ğŸ“Œ DescripciÃ³n del proyecto

Este proyecto presenta una **soluciÃ³n completa de Machine Learning (endâ€‘toâ€‘end)** para predecir la **calidad del vino tinto** a partir de sus propiedades fisicoquÃ­micas. El objetivo es construir, evaluar y desplegar un modelo de clasificaciÃ³n robusto y comunicar los resultados mediante un **dashboard interactivo en Streamlit**.

El proyecto estÃ¡ diseÃ±ado tanto como **ejercicio tÃ©cnico de ML** como **proyecto de portfolio**, adecuado para presentaciones, defensa de bootcamp y entrevistas tÃ©cnicas.

---

## ğŸ¯ Objetivos

* Analizar y comprender el dataset de Wine Quality (vino tinto)
* Tratar el **desbalanceo de clases** y evaluar tÃ©cnicas de remuestreo
* Entrenar y comparar distintos modelos de clasificaciÃ³n
* Optimizar el mejor modelo mediante **GridSearchCV**
* Interpretar el rendimiento usando mÃ©tricas adecuadas
* Desplegar el modelo final en una **aplicaciÃ³n interactiva con Streamlit**

---

## ğŸ“Š Dataset

* **Fuente:** UCI Machine Learning Repository â€“ Wine Quality Dataset (Red Wine)
* **Muestras:** 1.599 vinos
* **Variables:** 11 caracterÃ­sticas fisicoquÃ­micas
* **Variable objetivo:** `quality` (valores enteros de 3 a 8)

### Variables de entrada

* fixed acidity
* volatile acidity
* citric acid
* residual sugar
* chlorides
* free sulfur dioxide
* total sulfur dioxide
* density
* pH
* sulphates
* alcohol

---

## âš–ï¸ Desbalanceo de clases

La variable objetivo estÃ¡ **claramente desbalanceada**, concentrÃ¡ndose la mayorÃ­a de observaciones en las calidades **5 y 6**.

* Clases minoritarias: 3, 4, 7 y 8
* Se evaluÃ³ el uso de **SMOTE** para equilibrar las clases
* **ConclusiÃ³n:** SMOTE no mejorÃ³ la accuracy global, por lo que no se utilizÃ³ en el modelo final

---

## ğŸ¤– Modelos evaluados

Se entrenaron y compararon los siguientes modelos:

* RegresiÃ³n LogÃ­stica
* AdaBoost
* Gradient Boosting
* Random Forest
* XGBoost
* XGBoost + SMOTE

### ComparaciÃ³n de modelos (Accuracy)

| Modelo              | Accuracy |
| ------------------- | -------- |
| RegresiÃ³n LogÃ­stica | 0.56     |
| AdaBoost            | 0.55     |
| Gradient Boosting   | 0.64     |
| **Random Forest**   | **0.68** |
| XGBoost             | 0.66     |
| XGBoost + SMOTE     | 0.66     |

---

## ğŸŒ² Modelo final â€“ Random Forest

El **Random Forest Classifier** fue seleccionado por ofrecer el mejor equilibrio entre rendimiento y estabilidad.

### Mejores hiperparÃ¡metros (GridSearchCV)

* `n_estimators`: 200
* `max_depth`: 20
* Accuracy en test: **0.68**

### MÃ©tricas de evaluaciÃ³n

* Accuracy (train y test)
* Matriz de confusiÃ³n
* Classification report (precisiÃ³n, recall y F1â€‘score)

---

## ğŸ”® AplicaciÃ³n Streamlit

Se desarrollÃ³ un **dashboard interactivo en Streamlit** para presentar los resultados y permitir predicciones en tiempo real.

### Funcionalidades principales

* VisiÃ³n general del dataset
* EstadÃ­sticas descriptivas
* Mapa de calor de correlaciones
* AnÃ¡lisis de desbalanceo de clases
* Comparativa de modelos
* Matriz de confusiÃ³n y classification report
* **PredicciÃ³n interactiva de la calidad del vino**
* Feedback visual mediante **imÃ¡genes asociadas a cada nivel de calidad**

---

## ğŸ–¼ï¸ Mejora visual

Cada valor de calidad predicho se asocia a una imagen representativa:

* Baja calidad â†’ imÃ¡genes mÃ¡s oscuras y menos atractivas
* Alta calidad â†’ imÃ¡genes premium y elegantes

Esto mejora la interpretabilidad y hace la aplicaciÃ³n mÃ¡s intuitiva para usuarios no tÃ©cnicos.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

* Python 3
* pandas, numpy
* scikitâ€‘learn
* XGBoost
* matplotlib, seaborn
* Streamlit
* pickle

---

## ğŸš€ CÃ³mo ejecutar el proyecto

### 1ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Ejecutar la aplicaciÃ³n Streamlit

```bash
python -m streamlit run streamlit_app.py
```

---

## ğŸ“ Estructura del proyecto

```
Red_wine_quality/
â”‚â”€â”€ streamlit_app.py
â”‚â”€â”€ winequality-red.csv
â”‚â”€â”€ random_forest_gs.pkl
â”‚â”€â”€ images/
â”‚   â”œâ”€â”€ wine_banner.jpg
â”‚   â”œâ”€â”€ quality_3.jpg
â”‚   â”œâ”€â”€ quality_4.jpg
â”‚   â”œâ”€â”€ quality_5.jpg
â”‚   â”œâ”€â”€ quality_6.jpg
â”‚   â”œâ”€â”€ quality_7.jpg
â”‚   â””â”€â”€ quality_8.jpg
â”‚â”€â”€ README.md
```

---

## ğŸ§  Conclusiones clave

* Los modelos ensemble superan a los modelos lineales en este dataset
* El desbalanceo de clases debe evaluarse mÃ¡s allÃ¡ de la accuracy
* Los dashboards interactivos mejoran la comunicaciÃ³n de resultados
* Random Forest ofrece un excelente equilibrio entre rendimiento e interpretabilidad

---

## ğŸ‘©â€ğŸ’» Autora

**Itxaso Campos Molina**
InterÃ©s en Data Science y Machine Learning
ğŸ“§ Email: [itxas.77@gmail.com](mailto:itxas.77@gmail.com)

---

## ğŸ“Œ Posibles mejoras futuras

* Enfoque de regresiÃ³n para predecir calidad continua
* Interpretabilidad con valores SHAP
* CalibraciÃ³n del modelo y aprendizaje sensible al coste
* Despliegue en Streamlit Cloud u otra plataforma

---

ğŸ· *Este proyecto combina ciencia de datos, machine learning y comunicaciÃ³n visual para transformar datos en conocimiento accionable.*
